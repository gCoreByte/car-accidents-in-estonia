{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports, global variables and SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "#pd.set_option('display.max_columns', 500)\n",
    "#pd.set_option('display.width', 1000)\n",
    "#pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "\n",
    "filename = \"file.csv\"\n",
    "\n",
    "columns_to_remove = \"kolumnid.txt\"\n",
    "\n",
    "data = pd.DataFrame(pd.read_csv(filename, sep=\";\"))\n",
    "\n",
    "\n",
    "\n",
    "########################################################SETTINGS########################################################\n",
    "\n",
    "#Set true to use openstreetmaps to convert gps coordinates to addresses when the Address field is being corrected.\n",
    "generate_missing_address_from_coords_online = False\n",
    "\n",
    "#Set true to use openstreetmaps to convert addresses to gps coordinates when the GPS  fields are being corrected.\n",
    "generate_missing_coords_from_address_online = True\n",
    "\n",
    "#Set true to convert all coordinates from L-EST97 to WGS-84\n",
    "do_convert_coordinates = True\n",
    "\n",
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing columns we do not need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(columns_to_remove, encoding = \"UTF-8\") as file:\n",
    "    for line in file:\n",
    "        var = line.strip().split(\"|\")\n",
    "\n",
    "        if var[2].strip() == \"drop\":\n",
    "            data = data.drop(columns=f\"{var[1].strip()}\")\n",
    "            print(f\"[{var[0].strip()}] Column {var[1].strip()} was dropped.\")\n",
    "        else:\n",
    "            print(f\"[{var[0].strip()}] Column {var[1].strip()} was not dropped.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing each column in the dataset:\n",
    "\n",
    "Fix column \"Juhtumi nr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all non-numeric characters in \"Case numbers\" column with zeroes.\n",
    "data['Juhtumi nr'] = data['Juhtumi nr'].str.replace(pat=r'\\D', repl='1', regex=True)\n",
    "data.rename(columns={'Juhtumi nr' : 'Case'}, inplace=True)\n",
    "\n",
    "#Convert to int64\n",
    "data['Case'] = data['Case'].astype('int64')\n",
    "\n",
    "#check\n",
    "data['Case'].describe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix 'Toimumisaeg'. separate dates and times to separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Date\"], data[\"Time\"] = data[\"Toimumisaeg\"].str.split(\" \", 1).str\n",
    "\n",
    "data = data.drop(\"Toimumisaeg\", axis=1)\n",
    "\n",
    "#data['Time'] = pd.to_datetime(data['Time'], format='%H:%M').apply(pd.Timestamp).dt.time\n",
    "\n",
    "print(data['Date'].describe)\n",
    "print(data['Time'].describe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix \"isikuid\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename column\n",
    "data.rename(columns={'Isikuid' : 'Involved'}, inplace=True)\n",
    "\n",
    "#Fix null/nan values\n",
    "print(\"Count of null values: \", data['Involved'].isna().sum())\n",
    "data.loc[data['Involved'].isna(), 'Involved'] = data['Hukkunuid'] + data['Vigastatuid']\n",
    "data['Involved'].fillna(0, inplace=True)\n",
    "print(\"Count of null values: \", data['Involved'].isna().sum())\n",
    "\n",
    "#Set type as int64\n",
    "data['Involved'] = data['Involved'].astype('int64', errors='ignore')\n",
    "\n",
    "#check results\n",
    "print(data['Involved'].value_counts(normalize=False, dropna=False))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix \"hukkunuid\" and \"vigastatuid\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Hukkunuid' : 'Dead', 'Vigastatuid' : 'Wounded'}, inplace=True)\n",
    "\n",
    "print(data['Dead'].value_counts(normalize=False, dropna=False))\n",
    "print(data['Wounded'].value_counts(normalize=False, dropna=False))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix 'Sõidukeid':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename column\n",
    "data.rename(columns={'Sõidukeid' : 'Vehicles'}, inplace=True)\n",
    "\n",
    "#Fill null values\n",
    "data['Vehicles'].fillna(0, inplace=True)\n",
    "\n",
    "#Fix type\n",
    "data['Vehicles'] = data['Vehicles'].astype('int64', errors='ignore')\n",
    "\n",
    "#Check\n",
    "print(data['Vehicles'].value_counts(normalize=False, dropna=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import requests\n",
    "import json\n",
    "import folium\n",
    "from IPython.display import display\n",
    "import pyproj\n",
    "import time\n",
    "\n",
    "COUNT_CONV = 0\n",
    "COUNT_GPS = 0\n",
    "\n",
    "def incrementConversions():\n",
    "    global COUNT_CONV\n",
    "    COUNT_CONV = COUNT_CONV + 1\n",
    "\n",
    "def incrementCoords():\n",
    "    global COUNT_GPS\n",
    "    COUNT_GPS = COUNT_GPS + 1\n",
    "\n",
    "\n",
    "def get_lat_lon(address):\n",
    "    # Set up the URL template\n",
    "    url = \"https://nominatim.openstreetmap.org/search?format=json&q={}\"\n",
    "\n",
    "    # Replace spaces in the address with \"+\" characters\n",
    "    address = address.replace(\" \", \"+\")\n",
    "\n",
    "    # Format the URL with the address\n",
    "    url = url.format(address)\n",
    "\n",
    "    # Send the request and get the response data\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    # Check if the data list is empty\n",
    "    if not data:\n",
    "        # If the data list is empty, return None\n",
    "        return (None, None)\n",
    "\n",
    "    # Extract the latitude and longitude from the response data\n",
    "    lat = data[0][\"lat\"]\n",
    "    lon = data[0][\"lon\"]\n",
    "\n",
    "    # Return the latitude and longitude as a tuple\n",
    "    incrementCoords()\n",
    "    print(COUNT_GPS, lat, lon)\n",
    "    return (lat, lon)\n",
    "\n",
    "\n",
    "def show_map(lat, lon):\n",
    "    # Import the necessary modules\n",
    "\n",
    "    # Create a Map object\n",
    "    m = folium.Map(location=[lat, lon], zoom_start=17)\n",
    "\n",
    "    # Display the map\n",
    "    display(m)\n",
    "\n",
    "\n",
    "# Set up the L-EST97 projection using the pyproj.Proj class\n",
    "l_est97 = pyproj.Proj(init='epsg:3301')\n",
    "# Set up the WGS-84 projection using the pyproj.Proj class\n",
    "wgs84 = pyproj.Proj(init='epsg:4326')\n",
    "def convert_coordinates(x, y):\n",
    "    # Convert the easting and northing coordinates from L-EST97 to WGS-84 using the pyproj.transform method\n",
    "    lon, lat = pyproj.transform(l_est97, wgs84, y, x)\n",
    "\n",
    "    incrementConversions()\n",
    "    print(COUNT_CONV, \"Old: \", x, y, \" New: \", lat, lon)\n",
    "    return lat, lon\n",
    "\n",
    "\n",
    "def get_address(lat, lon):\n",
    "    # Set up the URL template\n",
    "    url = \"https://nominatim.openstreetmap.org/reverse?format=json&lat={}&lon={}\"\n",
    "\n",
    "    # Format the URL with the latitude and longitude\n",
    "    url = url.format(lat, lon)\n",
    "\n",
    "    # Send the request and get the response data\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract the address from the response data\n",
    "    address = data.get(\"display_name\", \"\")\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Return the address\n",
    "    return address\n",
    "\n",
    "\n",
    "def create_address(est_lat, est_lon):\n",
    "    coords = convert_coordinates(est_lat, est_lon)\n",
    "\n",
    "    #Create address from coords and return it.\n",
    "    return get_address(coords[0], coords[1])\n",
    "\n",
    "\n",
    "def update_lat_lon(row):\n",
    "    # Convert the coordinates\n",
    "    t = convert_coordinates(row['Latitude'], row['Longitude'])\n",
    "    \n",
    "    #Return converted coordinates as series\n",
    "    return pd.Series({\"Latitude\": t[0], \"Longitude\": t[1]})\n",
    "\n",
    "\n",
    "def update_lat_lon_from_address(address):\n",
    "    #Get cords from address\n",
    "    lat, lon = get_lat_lon(address)\n",
    "    #return coords as a series\n",
    "    return pd.Series({\"Latitude\": lat, \"Longitude\": lon})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test getting cords of Delta Center\n",
    "#coords = get_lat_lon('Narva mnt 18 51009 Tartu')\n",
    "#print(coords[0], coords[1])\n",
    "#show_map(coords[0], coords[1])\n",
    "\n",
    "#The location should be: Harju maakond Tallinn Kesklinna linnaosa Estonia pst\n",
    "x = 6588678.0\t\n",
    "y = 542647.0\n",
    "cords = convert_coordinates(x, y)\n",
    "print(cords)\n",
    "show_map(cords[0], cords[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix \"Aadress PPA\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename column\n",
    "data.rename(columns={'Aadress (PPA)' : 'Address'}, inplace=True)\n",
    "\n",
    "\n",
    "print(\"Count of null values in Address column pre modification: \", data['Address'].isnull().sum())\n",
    "\n",
    "#Create a temp column we use to quantify rows\n",
    "data.insert(1, \"Temp\", \"\")\n",
    "\n",
    "#The ones with gps but no address can use gps as we use primarily gps in our project\n",
    "data['Temp'] = np.where((data[\"GPS X\"].notnull()) & (data[\"GPS Y\"].notnull() & (data[\"Address\"].isnull())), \"ONLY GPS\", data['Temp'])\n",
    "\n",
    "#The ones without gps but with address can have their gps constructed\n",
    "data['Temp'] = np.where((data[\"GPS X\"].isnull()) & (data[\"GPS Y\"].isnull() & (data[\"Address\"].notnull())), \"ONLY ADDRESS\", data['Temp'])\n",
    "\n",
    "#The ones without any location data will be dropped\n",
    "data['Temp'] = np.where((data[\"GPS X\"].isnull()) & (data[\"GPS Y\"].isnull() & (data[\"Address\"].isnull())), \"NOTHING\", data['Temp'])\n",
    "\n",
    "print(\"Count of null values in Address column post modification: \", data['Address'].isnull().sum())\n",
    "print()\n",
    "print(\"Count of null values with only GPS data and no address: \", len(data[data['Temp'] == \"ONLY GPS\"]))\n",
    "print(\"Count of rows with only Address data and no gps: \", len(data[data['Temp'] == \"ONLY ADDRESS\"]))\n",
    "print(\"Count of null values with NO location data at all: \", len(data[data['Temp'] == \"NOTHING\"]))\n",
    "\n",
    "print()\n",
    "\n",
    "#Drop the rows with no location data\n",
    "data = data[data['Temp'] != \"NOTHING\"]\n",
    "\n",
    "#Adds addresses to the rows that have only gps\n",
    "if generate_missing_address_from_coords_online:\n",
    "    data.loc[data[\"Temp\"] == \"ONLY GPS\", \"Address\"] = data.apply(lambda row: create_address(row[\"GPS X\"], row[\"GPS Y\"]), axis=1)\n",
    "print(\"Count of null values in Address column post modification: \", data['Address'].isnull().sum())\n",
    "\n",
    "#Drop the ones we could not generate and address for\n",
    "data = data[data['Address'] != \"\"]\n",
    "\n",
    "#Finally, remove any remaining rows where address remained null\n",
    "data = data[pd.notnull(data['Address'])]\n",
    "\n",
    "\n",
    "print(\"Count of null values in Address column after we drop the rows we could not get addresses for: \", data['Address'].isnull().sum())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix \"Liiklusõnnetuse liik [3]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename column\n",
    "data.rename(columns={'Liiklusõnnetuse liik [3]' : 'Type'}, inplace=True)\n",
    "\n",
    "print(data['Type'].value_counts(normalize=False, dropna=False))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing the parttaker fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix column names\n",
    "data.rename(columns={\n",
    "'Kergliikurijuhi osalusel' : 'Involved_lightmover',\n",
    "'Jalakäija osalusel' : 'Involved_pedestrian',\n",
    "'Kaassõitja osalusel' : 'Involved_passenger',\n",
    "'Maastikusõiduki juhi osalusel' : 'Involved_offroad_vehicle',\n",
    "'Eaka (65+) mootorsõidukijuhi osalusel' : 'Involved_elderly',\n",
    "'Bussijuhi osalusel' : 'Involved_busdriver',\n",
    "'Veoautojuhi osalusel' : 'Involved_truckdriver',\n",
    "'Ühissõidukijuhi osalusel' : 'Involved_public_transport_driver',\n",
    "'Sõiduautojuhi osalusel' : 'Involved_car_driver',\n",
    "'Mootorratturi osalusel' : 'Involved_motorbike_driver',\n",
    "'Mopeedijuhi osalusel' : 'Involved_moped_driver',\n",
    "'Jalgratturi osalusel' : 'Involved_biker',\n",
    "'Alaealise osalusel' : 'Involved_minor',\n",
    "'Turvavarustust mitte kasutanud isiku osalusel' : 'Involved_not_wore_seatbelt',\n",
    "'Esmase juhiloa omaniku osalusel' : 'Involved_learner_driver',\n",
    "'Mootorsõidukijuhi osalusel' : 'Involved_vehicle_driver',\n",
    "}, inplace=True)\n",
    "\n",
    "cols = [\n",
    "'Involved_lightmover',\n",
    "'Involved_pedestrian',\n",
    "'Involved_passenger',\n",
    "'Involved_offroad_vehicle',\n",
    "'Involved_elderly',\n",
    "'Involved_busdriver',\n",
    "'Involved_truckdriver',\n",
    "'Involved_public_transport_driver',\n",
    "'Involved_car_driver',\n",
    "'Involved_motorbike_driver',\n",
    "'Involved_moped_driver',\n",
    "'Involved_biker',\n",
    "'Involved_minor',\n",
    "'Involved_not_wore_seatbelt',\n",
    "'Involved_learner_driver',\n",
    "'Involved_vehicle_driver']\n",
    "\n",
    "#replace nans with 0-s, set all values to be if type int and remove any nan-s that might have popped up during that operation aswell\n",
    "data[cols] = data[cols].replace(np.nan, 0)\n",
    "data[cols] = data[cols].apply(pd.to_numeric, errors=\"coerce\", downcast=\"integer\")\n",
    "data[cols] = data[cols].replace(np.nan, 0)\n",
    "\n",
    "#verify results\n",
    "for c in cols:\n",
    "    print(data[c].value_counts(normalize=False, dropna=False))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the road situation columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix column names\n",
    "data.rename(columns={\n",
    "'Tee tüüp [2]':'Road_type',\n",
    "'Tee element [1]':'Feature',\n",
    "'Kurvilisus' : 'Curvature',\n",
    "'Tee tasasus':'Levelness',\n",
    "'Tee seisund':'Road_condition',\n",
    "'Teekatte seisund [2]':'Surface_condition',\n",
    "'Lubatud sõidukiirus (PPA)':'Speed_limit'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "cols = [\n",
    "'Road_type',\n",
    "'Feature',\n",
    "'Curvature',\n",
    "'Levelness',\n",
    "'Road_condition',\n",
    "'Surface_condition',\n",
    "'Speed_limit'\n",
    "]\n",
    "\n",
    "#Set 0 speed limits as NaN as Estonia has no motorways without speed limits\n",
    "data['Speed_limit'] = data['Speed_limit'].replace(0, np.nan)\n",
    "\n",
    "#Fix a probable typo\n",
    "data['Speed_limit'][data['Speed_limit'] == 901] = 90\n",
    "\n",
    "\n",
    "#check results\n",
    "print(data.shape)\n",
    "print()\n",
    "for c in cols:\n",
    "    print(data[c].value_counts(normalize=False, dropna=False))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix weather and lighting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix column names\n",
    "data.rename(columns={\n",
    "'Ilmastik [1]':'Weather',\n",
    "'Valgustus [2]':'Lighting'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "cols = ['Weather', 'Lighting']\n",
    "\n",
    "#data = data.dropna(subset=cols)\n",
    "\n",
    "#check results\n",
    "print(data.shape)\n",
    "print()\n",
    "for c in cols:\n",
    "    print(data[c].value_counts(normalize=False, dropna=False))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix gps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix column names\n",
    "data.rename(columns={\n",
    "'GPS X':'Latitude',\n",
    "'GPS Y':'Longitude'\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"Latitude nan count: \", data['Latitude'].isna().sum(), \"Longitude nan count: \", data['Longitude'].isna().sum())\n",
    "\n",
    "#first we must convert all we can, then create coords for the rows that have address, afterwards drop rest what we cant generate for\n",
    "\n",
    "#Convert all coordinates from L-EST97 to WGS-84\n",
    "if do_convert_coordinates:\n",
    "    print(\"Now vonverting co-ordinates >>> \")\n",
    "    data[[\"Latitude\", \"Longitude\"]] = data.apply(update_lat_lon, axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "#Try to generate missing coordinates from address data if permitted\n",
    "if generate_missing_coords_from_address_online:\n",
    "    print(\"Now generating co-ordinats from Address-es >>> \")\n",
    "    #data[[\"Latitude\", \"Longitude\"]] = data.apply(lambda row: update_lat_lon_from_address(row[\"Address\"]), axis=1)\n",
    "    # Select the rows where the \"Temp\" column has the value \"ONLY ADDRESS\", so we know which rows to try to create coords for\n",
    "    rows = data.loc[data[\"Temp\"] == \"ONLY ADDRESS\"]\n",
    "    # Apply the update_lat_lon_from_address() function to the selected rows\n",
    "    rows[[\"Latitude\", \"Longitude\"]] = rows.apply(lambda row: update_lat_lon_from_address(row[\"Address\"]), axis=1)\n",
    "    data.update(rows)\n",
    "\n",
    "\n",
    "#Finally remove any nan-s from rows where we did not generate coords from address or where generating was impossible\n",
    "cols = ['Latitude', 'Longitude']\n",
    "data = data.dropna(subset=cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove temp column and drop any last nan rows, plus output the dataframe to a new csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Temp'], axis=1, inplace=True)\n",
    "#data.dropna(inplace=True)\n",
    "\n",
    "data.to_csv('cleaned_data_file.csv', encoding='utf-8', index=False, header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape', data.shape)\n",
    "print(\"Latitude nan count: \", data['Latitude'].isna().sum(), \"Longitude nan count: \", data['Longitude'].isna().sum())\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "432912b4a3d61698e775b0afd7eed56c874724ab6c455817cadfb90cd0d31947"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
